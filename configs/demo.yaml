# Demo configuration for quick end-to-end test
model_name: "distilgpt2"
output_dir: "outputs/demo"

data:
  use_dummy_data: true
  num_samples: 10
  train_ratio: 0.8
  max_length: 256
  analyze_data: true

training:
  num_epochs: 1
  batch_size: 2
  learning_rate: 1e-5
  weight_decay: 0.01
  save_every: 1

ppo:
  learning_rate: 1e-6
  batch_size: 2
  ppo_epochs: 2
  clip_ratio: 0.2
  kl_coef: 0.05
  entropy_coef: 0.01
  max_gen_length: 64
  temperature: 1.0
  num_epochs: 1

grpo:
  learning_rate: 1e-6
  group_size: 2
  kl_coef: 0.05
  max_gen_length: 64
  temperature: 1.0
  num_epochs: 1

dpo:
  learning_rate: 5e-7
  batch_size: 2
  beta: 0.1
  num_epochs: 1

evaluation:
  num_samples: 5
  use_gpt4_judge: false
